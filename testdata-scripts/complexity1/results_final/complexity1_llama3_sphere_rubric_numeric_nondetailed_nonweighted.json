[
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_1.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "1"
        },
        "raw_response": "----------------------------------------------------------------------------- \nFunctionality: 5, Logic: 5, Code Quality: 4, User Input Handling: 3, Documentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_2.py",
        "scores": {
            "Functionality": "2",
            "Logic": "1",
            "Code Quality": "2",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "----------------------------------------------------------------------------- \nFunctionality: 2\nLogic: 1\nCode Quality: 2\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_3.py",
        "scores": {
            "Functionality": "4",
            "Logic": "3",
            "Code Quality": "2",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "<start of response>\nFunctionality: 4, Logic: 3, Code Quality: 2, User Input Handling: 1, Documentation: 1 </end of response>"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_4.py",
        "scores": {
            "Functionality": "4",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "1",
            "Documentation": "3"
        },
        "raw_response": "Functionality: 4\nLogic: 5\nCode Quality: 4\nUser Input Handling: 1\nDocumentation: 3"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_5.py",
        "scores": {
            "Functionality": "4",
            "Logic": "3",
            "Code Quality": "2",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 4\nLogic: 3\nCode Quality: 2\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_6.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_7.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_8.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_9.py",
        "scores": {
            "Functionality": "4",
            "Logic": "4",
            "Code Quality": "3",
            "User Input Handling": "1",
            "Documentation": "2"
        },
        "raw_response": "Functionality: 4\nLogic: 4\nCode Quality: 3\nUser Input Handling: 1\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_1_10.py",
        "scores": {
            "Functionality": "2",
            "Logic": "1",
            "Code Quality": "3",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 2\nLogic: 1\nCode Quality: 3\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_1.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "3"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 3"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_2.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_3.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_4.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_5.py",
        "scores": {
            "Functionality": "4",
            "Logic": "4",
            "Code Quality": "3",
            "User Input Handling": "1",
            "Documentation": "1"
        },
        "raw_response": "Functionality: 4\nLogic: 4\nCode Quality: 3\nUser Input Handling: 1\nDocumentation: 1"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_6.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_7.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_8.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "----------------------------------------------------------------------------- \nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_9.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_2_10.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_1.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "----------------------------------------------------------------------------- \nFunctionality: 5, Logic: 5, Code Quality: 4, User Input Handling: 5, Documentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_2.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_3.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "1",
            "Documentation": "3"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 1\nDocumentation: 3"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_4.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_5.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "4"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 4"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_6.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "4"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 4"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_7.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "2"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 2"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_8.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_9.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "4"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 4"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_3_10.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "3",
            "Documentation": "4"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 3\nDocumentation: 4"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_1.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_2.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "1",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 1\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_3.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_4.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_5.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_6.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_7.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_8.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_9.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "5",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 5\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_4_10.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_1.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_2.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "5",
            "User Input Handling": "4",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 5\nUser Input Handling: 4\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_3.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_4.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_5.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_6.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_7.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "5",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 5\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_8.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "-----------------------------------------------------------------------------\n\n\nFunctionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_9.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    },
    {
        "modelname": "llama3",
        "rubricfilename": "sphere_rubric_numeric_nondetailed_nonweighted.txt",
        "assessmentfilename": "sphere_5_10.py",
        "scores": {
            "Functionality": "5",
            "Logic": "5",
            "Code Quality": "4",
            "User Input Handling": "5",
            "Documentation": "5"
        },
        "raw_response": "Functionality: 5\nLogic: 5\nCode Quality: 4\nUser Input Handling: 5\nDocumentation: 5"
    }
]